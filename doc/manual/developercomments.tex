Auto-WEKA has been designed to be relatively easy to extend with new optimisation methods/instance generators/machine learning algorithms. The core classes in Auto-WEKA all have JavaDoc, and comments throughout the code that should help explain what each bit does.

To add a new optimisation method, you need to provide three classes, an \classname{ExperimentConstructor}, a \classname{TrajectoryParser}, and a \classname{Wrapper}. The \classname{ExperimentConstructor} converts an experiment definition to an actual experiment file (by generating any extra data that is needed by the optimiser), while the \classname{TrajectoryParser} extracts the results of the optimiser into a format that can readily be used by the rest of the Auto-WEKA tools. The \classname{Wrapper} class provides a way to convert parameters from the optimiser into something that can be understood by Auto-WEKA (which in then turn is passed on to WEKA). This class is also responsible for reporting the error rate back to the optimiser, along with the time it took to train the classifier or regression method. Looking at the provided implementations for SMAC, TPE and IRace should be sufficient in determining how to write your own methods.

New instance generators can be created by extending \classname{autoweka.InstanceGenerator}, and just ensuring that they are on the classpath when you invoke the \classname{ExperimentConstructor}. Looking at the provided generators should be sufficient for creating your own, (which would allow you to build generators that don't require the entire dataset loaded into RAM).

Adding a new machine learning algorithm into Auto-WEKA is as simple as creating a new \file{.param} file in the appropriate subfolder under the \file{params} directory, and ensuring that your classifier is on Java's classpath when you invoke the \classname{ExperimentConstructor} or UI.
